{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch import nn \n",
    "from torchvision import models, transforms\n",
    "import torch.onnx \n",
    "import requests\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img = Image.open(\n",
    "    requests.get(\n",
    "        \"http://assets.myntassets.com/v1/images/style/properties/7a5b82d1372a7a5c6de67ae7a314fd91_images.jpg\", \n",
    "        stream=True)\\\n",
    "    .raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/anaconda3/envs/torch_cv_env/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/james/anaconda3/envs/torch_cv_env/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "base_model  = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = base_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.Resize((244)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=244, interpolation=bilinear, max_size=None, antialias=warn)\n",
       "    ToTensor()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = trans(sample_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 325, 244])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"models/vgg16.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_input = sample_input.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 325, 244])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_input_final = cuda_input.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.3843e-01, -1.1409e+00, -1.8003e+00, -1.9813e+00, -6.2103e-01,\n",
       "          1.4748e-01, -1.2773e+00, -1.4748e+00, -1.8193e+00, -3.3324e+00,\n",
       "         -2.6636e+00, -3.0319e+00, -2.6548e+00, -2.7222e+00, -1.4038e+00,\n",
       "         -2.6484e+00, -2.4838e+00, -1.9218e+00, -2.9215e+00, -1.9168e+00,\n",
       "         -2.8512e+00, -1.7300e+00, -3.0235e+00, -3.1577e+00, -2.0754e+00,\n",
       "         -2.2516e+00, -1.5841e+00, -1.1413e+00, -7.1804e-01, -1.9621e+00,\n",
       "         -2.3418e+00, -2.7144e+00, -1.7334e+00, -7.4089e-01, -2.2293e-01,\n",
       "         -1.9706e+00, -6.5241e-01, -1.3567e+00, -6.9290e-01, -2.1339e+00,\n",
       "         -2.0594e+00, -2.1832e+00, -2.9453e+00, -1.9408e+00, -1.8848e+00,\n",
       "         -1.1064e+00, -1.3633e+00, -1.1942e+00, -1.9714e+00, -2.2032e+00,\n",
       "          2.2160e-02, -1.1443e-01, -2.1405e-01, -6.3977e-01, -1.4040e+00,\n",
       "         -7.7976e-01, -2.2681e+00, -2.2844e+00, -1.9249e+00, -4.6367e-01,\n",
       "         -1.0582e+00, -1.4732e+00, -1.0486e+00, -7.1847e-01, -3.5748e-01,\n",
       "         -1.0640e+00, -1.1700e+00, -7.6011e-01, -1.9452e+00, -3.8692e-01,\n",
       "         -2.2682e+00, -1.1082e+00, -2.2105e+00, -2.2136e+00, -2.5142e+00,\n",
       "         -1.6508e+00, -1.1129e+00, -2.2545e+00, -5.2476e-02, -1.0831e+00,\n",
       "         -2.6848e+00, -2.4262e+00, -2.2227e+00, -2.9260e+00, -2.1112e+00,\n",
       "         -2.3197e+00, -1.7555e+00, -6.3855e-01, -6.2890e-01, -1.1825e+00,\n",
       "         -7.3077e-01, -1.2947e+00, -2.8061e+00, -2.7830e+00, -2.5028e+00,\n",
       "         -2.5845e+00, -2.3287e+00, -3.5464e+00, -3.0128e+00, -2.0650e+00,\n",
       "         -2.6451e+00, -7.5761e-01, -8.1581e-01, -1.4397e+00, -1.4607e+00,\n",
       "         -9.8928e-01, -3.7451e-01,  3.7193e-01, -1.4241e+00, -1.4234e-01,\n",
       "         -2.6355e+00,  1.3427e+00,  9.6438e-01, -1.2422e+00, -1.1324e+00,\n",
       "         -1.8648e+00, -1.1777e+00, -9.8157e-01, -6.8456e-01, -1.8979e+00,\n",
       "         -2.6372e+00, -1.3599e+00,  2.8427e-01, -9.3710e-01,  9.0176e-01,\n",
       "         -2.2951e+00, -1.0775e+00, -3.2063e+00, -2.7548e+00, -1.8345e+00,\n",
       "         -2.1247e+00, -1.9460e+00, -1.4495e+00, -1.8978e+00, -2.2566e+00,\n",
       "         -3.1385e+00, -2.0019e+00, -2.3446e+00, -1.7239e+00, -3.3894e+00,\n",
       "         -2.6799e+00, -2.7962e+00, -2.1937e+00, -3.6411e+00, -3.9648e+00,\n",
       "         -2.2263e+00, -2.3697e+00, -2.6303e+00, -1.3952e+00, -9.9229e-01,\n",
       "         -8.9077e-01,  1.3196e+00, -6.4202e-01,  1.3212e+00,  4.1666e-01,\n",
       "          3.4880e-01, -1.6424e-01,  7.2359e-02,  5.1680e-01,  4.6320e-01,\n",
       "          8.7715e-01,  2.9918e-01,  3.3207e-02,  1.7094e+00, -7.5316e-01,\n",
       "         -1.6794e-01, -8.2177e-01, -1.0996e+00,  9.8882e-01, -4.7972e-01,\n",
       "          8.0306e-02,  5.4851e-01, -3.5357e-01,  2.2771e-01, -1.0558e-01,\n",
       "          4.6525e-01, -2.0745e-01,  4.5589e-01,  7.8379e-01,  2.2770e-01,\n",
       "         -8.8944e-01, -3.0096e-02,  9.0715e-01,  1.2883e+00,  8.6716e-01,\n",
       "          7.8473e-01,  7.7666e-01,  1.0573e+00, -1.0832e-01, -4.3229e-02,\n",
       "          2.1325e-01,  3.5688e-01,  6.6926e-01,  1.2105e+00,  6.8895e-01,\n",
       "          6.5017e-01, -1.6555e-01,  8.2702e-01,  2.7794e-01,  1.0750e+00,\n",
       "          3.4175e-01, -1.4985e-01,  1.1636e+00,  1.3146e+00,  5.5931e-01,\n",
       "          3.6260e-01, -2.4152e-01,  6.9323e-01,  1.0141e+00,  9.1779e-02,\n",
       "         -6.8658e-01,  1.7960e+00, -6.1202e-01,  4.8713e-01,  3.9985e-01,\n",
       "         -1.7361e-01,  6.4979e-01, -4.7659e-01,  3.4192e-01,  1.0354e-01,\n",
       "          5.3689e-01, -6.4534e-01,  2.3061e-01,  3.5193e-01,  2.8017e-01,\n",
       "         -2.2144e-02,  8.8320e-01,  1.2790e-01,  6.6105e-01,  1.9476e-01,\n",
       "          5.0223e-02, -1.2151e+00, -1.5524e+00,  1.3786e+00,  6.7715e-01,\n",
       "          5.2199e-01, -1.7981e-02,  1.1583e+00,  8.6275e-01, -2.9997e-01,\n",
       "          3.0578e-01, -6.7348e-01,  3.5613e-01,  4.3868e-01,  5.7120e-01,\n",
       "          4.0033e-02,  3.8932e-02, -1.0738e-02, -8.9577e-01, -2.9130e-01,\n",
       "         -4.3383e-01, -1.9336e-01,  5.0475e-01,  8.6631e-01,  7.3584e-01,\n",
       "          3.4846e-01,  7.3163e-01,  4.1408e-01,  9.9460e-01,  6.2799e-01,\n",
       "          1.3777e+00, -1.5881e-01,  1.2828e+00, -1.3667e-01, -9.6016e-02,\n",
       "          1.3307e+00,  8.8098e-01,  4.8528e-01,  2.5935e-01, -1.0613e+00,\n",
       "          3.3559e-01, -1.3453e+00, -8.1421e-01,  4.8212e-01, -1.1255e+00,\n",
       "         -2.5801e+00, -1.1527e+00, -1.0598e+00, -1.5006e+00, -4.6069e-02,\n",
       "         -7.4449e-01,  1.0766e-01,  4.1544e-01, -1.3084e-01,  2.6951e-01,\n",
       "          8.4951e-01, -6.6138e-01, -5.5542e-01, -1.4501e+00, -2.5944e+00,\n",
       "         -1.8925e+00, -2.2655e+00, -1.2734e+00, -8.6920e-01, -1.2511e+00,\n",
       "         -1.2220e+00, -7.3023e-01, -2.1965e+00, -1.7688e+00, -6.3637e-01,\n",
       "         -3.0257e+00, -1.5260e+00, -1.5497e+00, -1.7522e+00, -2.5288e+00,\n",
       "         -2.2588e+00, -8.5462e-01, -2.6017e+00, -2.5073e+00, -1.5923e+00,\n",
       "         -8.6806e-01, -1.2617e+00, -1.1057e+00,  1.0265e+00, -5.7885e-01,\n",
       "         -1.2713e+00, -1.9082e+00, -2.3328e+00, -9.5333e-01, -8.8386e-01,\n",
       "         -2.1802e+00, -2.6278e+00, -1.4726e+00, -1.7047e+00, -2.5508e+00,\n",
       "         -1.5627e+00, -2.4819e+00,  1.6599e-01, -5.4357e-01, -1.2576e+00,\n",
       "         -6.2845e-01, -1.0969e+00,  4.2780e-01, -7.6933e-01, -9.6944e-01,\n",
       "         -2.1149e+00, -2.1397e+00, -5.5332e-01,  8.5897e-01, -7.6568e-01,\n",
       "         -1.8240e+00, -3.0040e-01, -2.2926e+00, -1.7728e+00, -2.4978e+00,\n",
       "         -2.1082e+00, -1.4342e+00, -2.6758e+00, -1.7018e+00, -2.4874e+00,\n",
       "         -2.3271e+00, -1.2236e+00, -1.6270e+00, -1.9392e+00, -8.3544e-01,\n",
       "         -1.0315e+00, -1.0532e-01, -8.7265e-01,  5.5692e-01, -4.0467e-01,\n",
       "         -2.0054e+00, -9.2697e-01, -1.3661e+00, -3.8047e-02, -1.2644e+00,\n",
       "         -9.6286e-01, -1.8182e+00, -6.0128e-01, -1.5683e+00, -1.7818e+00,\n",
       "         -1.5952e+00, -8.5390e-01, -1.4383e+00, -1.7637e+00, -2.3557e+00,\n",
       "         -2.7106e+00, -6.0377e-01, -1.7478e+00, -8.9565e-01, -1.2505e+00,\n",
       "         -5.2628e-01, -1.7105e+00, -1.3312e+00, -2.1639e+00, -2.3421e+00,\n",
       "         -5.0116e-01, -8.9048e-01, -2.3797e+00, -1.9581e+00,  4.3828e-01,\n",
       "         -1.7154e+00,  3.8107e-01, -2.4297e+00, -2.4483e+00, -3.3157e-01,\n",
       "          1.5178e+00, -2.5365e+00, -1.8568e+00,  1.4226e+00,  2.4448e+00,\n",
       "          4.6292e-01,  5.9215e-02,  6.5536e-01, -1.4210e+00, -2.3235e+00,\n",
       "         -7.3116e-01, -8.7951e-01, -1.7661e+00, -2.5065e+00,  1.2936e+00,\n",
       "         -7.5824e-01,  7.1852e+00, -5.3014e-03,  1.5572e-01,  3.3834e+00,\n",
       "          6.1285e-01,  3.8102e+00,  7.8544e-01,  2.8465e-01,  3.4090e+00,\n",
       "          1.4615e-01, -1.2778e-01,  1.8021e+00,  8.2300e-01,  3.9032e-02,\n",
       "         -9.7792e-01, -3.6573e-01, -1.1001e+00, -1.6057e-01, -7.0435e-01,\n",
       "         -5.4443e-01,  3.5374e+00,  2.4973e-01,  3.1732e+00,  4.1635e+00,\n",
       "          2.3366e+00, -9.7292e-01, -1.0168e+00,  1.7212e+00,  8.9842e-01,\n",
       "         -1.2696e-01, -1.4018e-01,  9.7895e-01,  3.3787e+00, -1.9204e-01,\n",
       "          2.0839e+00,  9.3190e-01,  1.0594e+00, -8.5552e-02, -1.6905e+00,\n",
       "         -2.0372e+00,  2.7718e+00,  3.2615e+00,  1.3993e+00,  1.2442e-01,\n",
       "         -1.4455e-01,  4.7545e-01,  4.1024e+00, -4.5900e-01,  3.8346e+00,\n",
       "         -1.1409e+00,  1.6966e+00,  2.3289e+00,  1.3715e+00,  2.5643e+00,\n",
       "          4.6358e+00, -8.1946e-01, -1.0181e+00, -1.2840e+00, -2.5039e-01,\n",
       "          2.1856e+00, -2.0067e+00, -1.2374e+00,  9.4819e-01,  7.2062e+00,\n",
       "         -2.2672e+00, -1.9055e+00,  5.8972e-01,  1.0523e+00, -1.0552e+00,\n",
       "          1.5081e+00,  5.8180e-01,  1.0268e+00, -2.5787e+00, -5.9527e-01,\n",
       "          1.3363e+00, -8.2161e-01,  2.3988e+00, -4.7227e-01, -6.0272e-01,\n",
       "          2.6834e+00, -2.6440e-01,  9.2978e-01,  1.7394e-01,  1.2608e+00,\n",
       "         -1.7810e-01,  1.4362e+00, -2.1726e+00, -1.7754e+00,  3.0800e+00,\n",
       "         -1.0659e+00,  2.4186e+00,  2.2547e+00,  1.0313e+00, -3.0441e-02,\n",
       "         -6.0196e-01, -5.5016e-02, -7.7051e-01,  1.1889e+00, -1.2029e-01,\n",
       "          8.2870e-02, -1.1075e+00, -7.2863e-01, -2.8117e-01,  3.5806e+00,\n",
       "          3.4557e+00,  2.6452e+00, -9.8149e-01,  1.0467e-01,  1.2235e+00,\n",
       "          2.8543e+00, -5.7293e-02,  2.4097e+00,  3.7211e+00,  1.3779e+00,\n",
       "         -8.7760e-01,  1.7054e+00,  6.4861e-01,  9.5724e-01,  4.1659e+00,\n",
       "          1.0517e+00,  2.0195e+00,  6.7262e-01,  2.0306e+00,  3.2741e+00,\n",
       "         -2.8083e+00, -1.3797e+00, -2.4970e+00,  2.8492e-01,  2.2358e+00,\n",
       "         -2.6072e-01,  6.4172e-01,  2.6455e+00,  3.4565e+00,  5.3171e-01,\n",
       "          1.4464e+00,  1.2201e+00, -2.9487e+00, -1.1865e-01,  2.1260e+00,\n",
       "         -2.6936e-01,  1.2182e+00,  2.0293e+00,  1.3905e+00, -1.1064e+00,\n",
       "         -1.9011e+00,  5.3651e-01, -1.1347e+00,  7.6872e-01,  1.9805e+00,\n",
       "         -7.1806e-01, -1.3991e+00, -2.2509e-01, -8.1828e-01, -1.2147e-01,\n",
       "         -2.1340e+00,  1.4899e-01,  8.0515e-02,  2.2892e+00, -1.6621e+00,\n",
       "          1.6324e+00, -1.3348e+00,  1.7468e-01, -2.3386e+00,  1.7660e+00,\n",
       "         -1.8061e-01, -2.0877e+00,  1.1109e+00,  3.8680e+00,  1.7700e+00,\n",
       "         -4.6044e-02, -2.5490e+00, -5.3894e-01,  1.0144e-02,  2.1628e+00,\n",
       "          2.2770e+00, -1.0279e+00,  1.7255e+00,  3.2916e+00,  2.3930e+00,\n",
       "          2.4833e+00,  4.1362e+00, -2.9099e-01,  1.2211e+00,  4.5775e-01,\n",
       "         -1.4712e+00,  1.2174e+00,  1.5844e+00, -1.2354e+00,  1.2751e+00,\n",
       "          1.2433e+00,  4.8667e+00,  1.6482e+00, -2.9224e+00,  2.9499e-01,\n",
       "          1.6013e+00,  3.7565e+00, -4.0669e-01,  5.9102e+00, -1.2945e+00,\n",
       "          7.1650e+00,  1.9033e+00, -1.1613e+00,  1.2894e+00,  3.2724e+00,\n",
       "          3.3444e+00, -4.5047e-01,  4.3052e+00,  5.2329e-01,  1.1678e+00,\n",
       "          3.1522e+00,  1.2518e-01,  2.6986e-01, -2.2265e-01,  2.2246e-02,\n",
       "         -2.7265e+00,  1.5665e-01, -8.7033e-01, -7.2049e-01,  8.1305e-01,\n",
       "          2.1733e+00,  1.2575e+00,  8.6312e-01,  2.7740e-01, -6.4949e-01,\n",
       "          6.8480e-01,  3.2926e+00, -1.2824e+00,  4.2850e+00,  3.9402e+00,\n",
       "         -7.9538e-01,  2.1567e+00,  2.9515e+00,  1.5674e+00,  1.0480e+00,\n",
       "         -1.7534e+00,  1.7078e+00,  1.8581e+00,  2.3023e-01, -1.0277e+00,\n",
       "          1.5260e+00,  1.1232e+00,  1.3709e+00, -3.6601e-01, -1.0379e+00,\n",
       "          6.9361e+00, -6.6857e-01, -1.2443e+00,  2.9574e+00,  7.9186e-01,\n",
       "         -2.0616e+00, -2.6657e+00,  1.3842e+00, -2.3155e+00,  1.5296e+00,\n",
       "         -1.6942e+00,  5.7066e-01,  1.4544e+00, -1.0105e+00,  2.1304e+00,\n",
       "         -1.1836e+00, -1.9583e+00, -7.5761e-02,  1.5156e+00,  9.7905e-01,\n",
       "         -8.3252e-01,  5.3770e-01,  1.0614e+00,  3.5395e+00,  1.3675e+00,\n",
       "          1.8036e+00,  3.4165e+00, -1.3459e+00,  1.3531e+00,  9.1820e-01,\n",
       "         -1.5023e+00, -9.9715e-01, -7.9353e-01,  1.7077e+00,  4.6893e+00,\n",
       "         -2.2828e+00,  5.5842e-01,  1.1229e+00,  9.4109e-01, -1.3423e+00,\n",
       "         -1.3633e+00,  2.7498e+00,  7.7197e+00, -1.8517e+00,  7.7190e-02,\n",
       "          1.9868e+00, -1.6167e-01,  2.8492e+00, -1.0796e-01, -1.4774e+00,\n",
       "         -2.7165e+00, -1.1868e+00, -2.8678e-01,  8.7163e-01,  1.1772e+00,\n",
       "         -7.6760e-01,  6.8471e-01,  2.0226e+00,  2.9535e+00,  6.7102e-01,\n",
       "         -1.0544e+00,  1.7037e+00, -2.2494e+00,  4.7900e-01,  1.4070e+00,\n",
       "          4.2109e-01,  3.0881e+00,  2.9676e+00,  6.5780e-02, -1.3070e+00,\n",
       "          8.5408e-01,  3.1587e-01,  3.7629e-01,  1.4113e+00,  1.1211e+00,\n",
       "         -1.7439e+00,  2.9993e+00,  9.1307e-01, -1.6216e-01, -2.2598e+00,\n",
       "          5.1247e+00,  1.4873e+00,  1.2980e-01,  9.0207e-01,  2.8837e+00,\n",
       "          1.5222e+00,  2.0031e+00,  1.2006e+00, -3.1444e-01, -1.4654e+00,\n",
       "          1.7792e+00, -4.0103e-02,  5.6986e-01,  1.9576e+00,  1.5211e+00,\n",
       "          2.3258e+00, -2.0285e+00,  1.8888e+00,  1.1414e+00,  8.6427e-01,\n",
       "          1.4527e+00, -1.5207e-01, -3.9566e-01,  9.3976e-01, -2.4175e-01,\n",
       "          1.9593e+00,  2.5062e+00, -8.0894e-01,  3.6277e-01,  8.6644e-01,\n",
       "          2.1163e+00,  2.4519e-01,  6.9224e-01, -7.1889e-01,  2.5789e+00,\n",
       "          1.4984e+00,  6.6015e-01,  1.6592e+00,  6.1915e-01,  1.6172e+00,\n",
       "          5.3527e+00,  1.3659e-01,  6.2276e-01,  3.3663e+00, -1.3015e+00,\n",
       "         -1.6286e-01, -4.8452e-02,  1.6354e+00,  5.0948e-01,  1.3364e+00,\n",
       "          1.3898e+00,  2.2869e+00, -5.4897e-01,  1.0298e+00,  1.6703e+00,\n",
       "          3.3107e+00,  1.2911e+00,  1.1210e+00,  3.9933e+00,  2.0045e+00,\n",
       "         -3.7241e-01,  2.1485e+00,  2.6749e+00,  2.6184e+00,  4.8393e-01,\n",
       "         -1.0069e+00,  3.5813e-01, -2.1110e+00, -2.4384e+00, -7.2623e-02,\n",
       "          1.2142e+00,  3.2705e+00,  6.8326e-01,  3.5258e+00,  2.4004e-01,\n",
       "          1.2084e+00,  1.3264e+00, -6.8804e-02,  2.4239e+00, -2.0113e+00,\n",
       "         -2.8857e-01,  9.1093e-01, -2.3435e+00,  1.0096e+00,  1.2504e+00,\n",
       "         -2.7966e+00, -7.7332e-01,  1.5997e+00,  3.6458e+00,  6.5722e+00,\n",
       "         -1.7991e+00,  9.6888e-01,  2.0328e-01,  1.7705e+00, -1.9567e+00,\n",
       "          5.1244e-01,  1.9918e+00, -5.8973e-01, -2.1121e+00,  4.6228e+00,\n",
       "         -6.3866e-01,  2.3942e+00,  3.6227e+00,  1.7658e+00,  1.5667e-02,\n",
       "          3.8835e+00,  5.5247e+00,  5.3259e+00,  8.8954e-01,  4.5027e-01,\n",
       "          1.6765e+00,  1.4525e+00, -1.7991e+00,  1.6539e+00,  1.7100e-01,\n",
       "          1.3934e+00,  1.8781e+00,  1.1832e+00, -5.6107e-02,  1.1542e+00,\n",
       "          8.8639e-01, -1.5498e+00, -1.3376e-01, -7.8821e-01,  7.1768e-01,\n",
       "         -3.2503e-01,  2.1349e+00,  1.2597e+00, -2.3867e+00, -3.0138e+00,\n",
       "          9.2928e-02, -1.6232e+00, -1.4578e+00,  3.3359e+00,  3.7485e+00,\n",
       "          1.6303e-01, -8.9737e-01,  8.9590e-01, -6.2420e-01, -2.8991e+00,\n",
       "          1.3721e-01,  2.2767e+00,  3.7671e-01,  5.9551e-01,  1.7850e+00,\n",
       "          9.5722e-01, -5.9288e-02,  1.9002e+00,  1.8483e+00, -1.0114e+00,\n",
       "          5.7647e+00,  1.3465e-01,  1.0011e+00, -1.9103e+00,  7.8625e-01,\n",
       "          2.9644e-01,  1.1098e-01,  1.8380e+00,  6.6622e-01,  2.3461e+00,\n",
       "         -2.5741e+00,  2.8447e-01,  1.9408e+00,  1.7127e+00,  1.1117e+00,\n",
       "         -1.6468e+00, -8.3391e-01,  9.8452e-01,  4.5046e+00,  2.6838e+00,\n",
       "          2.2719e+00,  4.0897e+00, -4.1161e-01, -1.5375e+00,  3.6722e-01,\n",
       "          1.6169e+00,  5.6951e+00, -3.3844e-01, -1.3604e+00, -5.2210e-01,\n",
       "         -6.9586e-01,  2.4666e+00,  5.9903e-01,  1.5761e+00, -7.5001e-01,\n",
       "         -1.9859e+00,  1.4825e+00,  6.8634e-01,  8.3126e-01,  1.9967e-01,\n",
       "         -1.2060e+00, -1.5385e+00, -3.5143e-01, -1.0852e-01,  2.2119e+00,\n",
       "         -8.8701e-01, -7.0092e-01, -9.2759e-01, -1.2196e+00, -3.6414e-01,\n",
       "         -7.0297e-01,  1.8211e+00,  9.5754e-01,  1.2518e-01,  1.8082e+00,\n",
       "         -1.3570e-02, -1.0920e+00, -4.1142e-01,  6.8703e-01, -1.4450e+00,\n",
       "         -1.3553e+00, -2.1361e+00,  3.3769e-01,  4.9448e-01, -6.2805e-02,\n",
       "         -1.2130e-01,  7.8099e-02, -6.7567e-01, -4.5156e-01, -2.7597e-01,\n",
       "          6.6534e-02, -5.4889e-01, -7.1564e-01,  1.6751e-01, -9.5676e-01,\n",
       "         -1.6979e+00,  1.3461e+00, -4.6987e-01, -1.0291e+00, -3.9033e-01,\n",
       "         -2.7825e-01,  5.8378e-01, -7.3214e-01,  2.4331e-01, -5.7225e-01,\n",
       "         -1.2358e+00,  3.5122e-01, -9.7128e-01, -9.6114e-01, -1.3441e+00,\n",
       "          2.5866e-01, -9.1340e-01,  6.1700e-01,  4.3893e-02, -8.9829e-01,\n",
       "         -5.8075e-01,  5.4549e-01,  1.2585e+00, -1.8048e+00,  9.9451e-01,\n",
       "         -1.5472e+00, -2.3633e+00,  1.0069e+00, -2.1432e+00, -1.7162e+00,\n",
       "         -1.0703e+00, -1.2417e+00, -1.2251e+00, -7.6081e-01, -8.4613e-01,\n",
       "         -1.1341e+00,  5.2384e-01, -1.1658e+00,  1.2279e+00,  2.7557e+00]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(cuda_input_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178608"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "244*244*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12288"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64*64*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math \n",
    "math.sqrt(4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cuda = x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cuda.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.9399e-01,  3.6448e+00, -1.4252e+00, -7.7867e-01,  8.7936e-01,\n",
       "          3.4538e+00,  3.1414e+00,  7.9657e-01,  6.6070e-01, -4.5570e-01,\n",
       "         -8.8170e-02,  2.2054e+00,  7.0811e-01,  3.3343e-01,  5.8564e-01,\n",
       "          1.3328e+00, -2.3455e+00, -1.5847e+00,  1.3300e+00, -1.0676e+00,\n",
       "         -1.2350e+00, -1.8543e+00, -1.9166e-01, -2.4735e-01, -1.3031e+00,\n",
       "         -1.7595e+00,  1.6076e-01, -1.1982e-01, -1.4511e+00,  4.6960e-01,\n",
       "         -1.5526e+00, -1.3142e+00, -2.5233e+00, -2.7358e-01, -2.9435e-03,\n",
       "         -9.7851e-01, -6.6806e-01, -1.7022e+00, -1.1097e+00, -1.7161e+00,\n",
       "          1.6548e-01, -2.2839e+00, -9.1546e-01, -8.3508e-01, -2.2171e+00,\n",
       "         -4.4755e-01,  6.5733e-01, -1.1186e+00, -4.4587e-01, -1.4346e+00,\n",
       "         -1.8483e-01, -2.4476e+00, -9.5768e-01, -1.6762e+00, -1.8545e+00,\n",
       "         -1.0092e+00, -2.9791e+00, -3.0366e+00,  1.4077e-01, -1.8119e+00,\n",
       "         -8.3329e-01, -2.9841e+00, -2.8301e+00, -1.0909e+00, -8.0770e-01,\n",
       "          1.7635e+00, -1.6432e+00, -1.6338e+00, -3.3393e+00, -7.2289e-01,\n",
       "          5.7171e-01,  2.5481e-01, -4.8337e-01,  4.2813e-01,  7.5314e-01,\n",
       "          5.6196e-01,  3.6187e-01,  1.4992e+00,  2.4821e+00,  1.6848e+00,\n",
       "         -7.5411e-01, -1.0076e+00, -6.3236e-01, -8.6056e-01,  4.5742e-01,\n",
       "         -3.2003e-01,  9.6868e-01, -1.4484e+00,  1.9320e+00, -1.0405e-01,\n",
       "          6.4306e-01, -3.6022e-01,  2.0267e+00, -3.8744e-01,  1.2400e-02,\n",
       "         -2.2614e+00,  2.0744e+00, -1.0070e+00, -2.4557e+00,  4.2268e-01,\n",
       "         -5.4994e-01, -7.1099e-01, -1.9918e+00,  7.5461e-02, -2.9902e-01,\n",
       "         -1.8630e+00, -1.8874e-01,  5.7086e+00,  3.8440e+00,  3.8290e+00,\n",
       "          3.4075e+00,  4.1944e+00,  1.1053e+00,  5.8749e-01,  8.0753e-01,\n",
       "          2.8632e+00,  1.9412e+00,  1.5358e+00,  2.1279e+00,  5.3697e-02,\n",
       "         -9.2802e-01,  2.2979e-01, -9.9737e-01,  7.4834e-02,  5.6077e-01,\n",
       "         -8.3153e-01,  1.4873e+00,  2.8777e-01, -1.9932e-01,  1.2443e+00,\n",
       "          1.1225e+00, -5.9691e-01,  1.4284e+00,  8.0697e-01,  1.5605e+00,\n",
       "         -7.0840e-01, -8.1410e-01, -1.2672e+00,  6.1125e-01, -2.1074e+00,\n",
       "         -2.0619e+00, -1.4524e+00, -1.4739e+00, -5.5310e-01, -1.1259e+00,\n",
       "          8.8785e-01, -2.0773e+00, -2.0366e+00, -1.0456e+00, -5.5469e-01,\n",
       "         -3.3477e-01,  5.9305e-01, -2.2229e+00, -2.9850e-01, -1.1748e+00,\n",
       "         -7.4067e-01, -7.7182e-01, -4.8123e-01, -7.6013e-01, -6.4894e-01,\n",
       "         -1.6586e+00, -3.3514e-01,  5.4122e-01,  2.0489e-01, -1.5236e+00,\n",
       "         -8.1024e-01, -1.2060e+00, -1.5972e+00, -4.6204e-01, -8.8436e-01,\n",
       "         -1.2188e+00, -9.5306e-01, -1.6128e+00, -6.7265e-02, -2.3342e+00,\n",
       "         -9.6821e-01, -2.0846e+00, -1.6208e+00, -6.1633e-01, -1.4598e+00,\n",
       "         -1.5936e+00, -6.4610e-01,  1.4354e-01, -1.0414e+00, -1.7446e-01,\n",
       "         -5.5369e-01, -2.0387e-01, -5.8132e-01, -1.2385e+00, -3.7000e-01,\n",
       "         -1.7572e+00,  9.3701e-01, -8.7401e-01,  5.1710e-01, -8.4005e-01,\n",
       "         -6.8023e-02, -1.1971e+00, -1.2935e+00, -2.2339e+00,  5.2216e-02,\n",
       "         -1.0248e+00, -1.5784e-01, -4.4501e-01,  1.6667e+00,  4.8502e-01,\n",
       "         -1.8286e+00, -1.4137e+00,  5.3102e-01, -6.8953e-01, -1.1795e+00,\n",
       "         -3.4467e+00,  6.2595e-01, -8.5165e-01,  1.0512e+00, -2.9442e-01,\n",
       "         -2.7960e-02, -8.9376e-01, -6.9946e-01, -2.1921e-01,  9.6916e-02,\n",
       "         -7.0891e-01,  3.0492e-01, -8.1535e-01, -6.7116e-01, -5.1088e-01,\n",
       "         -1.2494e+00, -1.6614e+00, -9.3885e-01, -1.2169e+00,  7.4051e-01,\n",
       "          6.4090e-01,  7.7271e-01, -8.2659e-01, -1.6153e+00,  6.9603e-01,\n",
       "         -5.1113e-01, -4.7599e-02, -6.2527e-02, -1.2917e-01, -3.8830e-01,\n",
       "          5.6881e-01, -3.0805e-01, -4.9774e-01, -1.5227e+00, -1.2859e+00,\n",
       "         -1.0595e+00, -2.9580e+00, -8.2874e-01, -1.1312e+00, -1.3834e+00,\n",
       "         -5.0937e-02, -1.3528e+00, -1.2905e+00,  2.7905e-01, -1.6534e-01,\n",
       "         -1.2171e+00, -8.9457e-01, -5.1744e-01,  2.6971e-01,  1.3360e+00,\n",
       "          1.4005e+00, -9.9397e-01, -1.8099e+00,  9.0419e-01, -1.1393e+00,\n",
       "          5.8312e-01, -1.3135e+00, -7.6129e-01, -3.6098e+00, -3.4525e-01,\n",
       "          6.2295e-01,  1.7988e+00,  6.8793e-01,  1.3403e+00,  1.4527e+00,\n",
       "         -8.8485e-01, -4.4853e-01,  2.0476e+00,  1.4062e-01,  1.2436e+00,\n",
       "          1.3593e+00, -6.2306e-01,  6.6313e-01,  6.9915e-01,  2.8046e-01,\n",
       "         -8.4769e-01,  3.0569e-01, -1.5631e+00, -1.0016e+00, -2.4518e+00,\n",
       "         -2.3009e+00, -3.3949e-01, -2.2720e-01,  2.7166e-01,  7.3528e-01,\n",
       "          5.8897e-01,  1.9296e+00, -4.5161e-01,  4.2642e-01,  1.2231e-01,\n",
       "         -2.4622e+00,  1.4204e+00, -4.0643e-01, -3.5427e-01, -7.1986e-02,\n",
       "         -1.7111e+00, -3.7139e-01, -9.2040e-02,  3.5101e-02,  1.7441e+00,\n",
       "          4.4433e+00, -1.1682e+00, -6.1055e-01,  1.8341e+00,  2.3765e+00,\n",
       "         -2.2508e-01, -1.6820e+00, -7.6156e-01,  1.2778e+00, -5.2771e-01,\n",
       "         -1.6094e+00, -2.7555e+00, -1.7283e+00, -5.6896e-01, -1.8756e+00,\n",
       "          1.3669e-01, -2.7471e+00,  2.5360e+00,  3.5684e+00,  2.8585e+00,\n",
       "          1.6118e-01,  1.2377e+00,  6.1775e-01,  6.4285e-01,  1.7922e+00,\n",
       "         -4.8971e-01, -1.0529e+00,  6.5308e-01,  8.0658e-01, -1.0818e+00,\n",
       "         -7.6627e-01, -9.7140e-02, -7.6663e-01, -2.2836e+00, -2.9773e-01,\n",
       "         -1.2629e-01, -1.3553e+00,  4.3260e-01, -1.5848e+00, -2.7264e+00,\n",
       "         -1.6764e+00, -2.1952e-01,  3.5994e-01,  1.0223e+00, -7.9790e-01,\n",
       "         -1.2616e+00, -2.4230e-02, -1.0233e+00, -5.5046e-01, -8.3137e-01,\n",
       "         -5.2764e-01,  3.2067e-01,  8.3657e-01, -9.7034e-01, -2.6541e+00,\n",
       "          1.3926e+00, -1.5853e+00, -9.4689e-01, -2.7375e-01, -1.4074e+00,\n",
       "          4.1740e-01,  3.6310e-01,  1.1491e-01, -6.8780e-01,  1.2132e+00,\n",
       "         -9.4993e-01,  3.0623e-01,  1.2341e+00,  2.3504e-01,  2.4024e-01,\n",
       "          8.1958e-01,  8.1124e-01,  1.2702e+00, -6.6672e-01, -1.1349e+00,\n",
       "         -6.3675e-02, -1.3161e+00,  7.1158e-02, -1.0405e+00, -7.4316e-02,\n",
       "          1.5624e+00,  1.4811e+00,  2.5940e+00,  1.7223e+00, -7.9556e-01,\n",
       "          8.1374e-01,  8.6619e-01,  3.9176e-01, -4.4790e-01,  1.9873e+00,\n",
       "         -1.1039e+00, -8.1370e-01,  3.5049e-01, -3.2360e+00, -1.7604e+00,\n",
       "         -5.5516e-01,  3.3353e-03, -2.2931e+00, -4.0268e+00,  2.4962e+00,\n",
       "          7.6705e-01,  2.9655e+00,  1.3689e+00, -1.4804e+00,  7.6011e-01,\n",
       "         -5.6372e-01, -1.2626e-02,  2.4993e+00, -1.6555e-01,  3.3504e-01,\n",
       "          4.1912e-02,  1.1755e+00, -1.2160e+00, -1.4762e+00, -8.5840e-03,\n",
       "          1.9390e+00, -2.3236e-01,  1.4086e+00,  1.2757e+00,  9.2712e-01,\n",
       "          8.7695e-01, -1.5507e+00,  1.2665e-01,  1.9012e+00,  2.0424e+00,\n",
       "          1.5605e+00, -2.5305e+00,  1.0252e+00,  3.0138e-02, -3.6785e-01,\n",
       "          3.7867e-01,  2.5429e+00, -9.6121e-01,  2.6099e+00, -1.3631e-01,\n",
       "          9.8540e-02,  3.2894e+00, -2.1675e-01, -4.0591e-02, -1.0011e+00,\n",
       "         -3.5637e+00,  3.3505e-01,  2.3166e+00, -2.2739e+00, -1.7392e+00,\n",
       "          1.0096e+00, -9.0134e-01, -1.0325e-01,  1.9598e+00,  5.7050e-01,\n",
       "         -1.2306e+00,  1.5885e+00,  2.5579e+00,  1.5514e+00, -4.0757e-01,\n",
       "         -1.5693e+00, -3.1538e+00, -7.5172e-01,  2.3437e-02,  1.9367e+00,\n",
       "          2.5296e+00, -1.2099e+00, -5.8283e-01, -2.6193e+00,  1.4270e+00,\n",
       "          1.1832e+00, -1.1533e+00, -2.4891e+00, -6.9101e-01, -1.9252e+00,\n",
       "          1.3278e+00, -1.0462e+00, -1.6211e+00, -1.5752e+00, -1.3851e+00,\n",
       "          2.8947e-01,  9.2084e-01,  2.9615e-01,  2.1946e+00,  3.9091e+00,\n",
       "          3.3813e+00, -1.5338e+00, -1.7242e-01, -1.2720e-01,  1.4143e+00,\n",
       "         -2.3229e+00,  6.7026e-01,  1.1404e+00, -3.0261e-01, -3.9704e-01,\n",
       "         -1.0917e+00,  2.4144e+00, -1.1179e+00, -6.7710e-01,  6.3847e-01,\n",
       "         -5.4608e-01,  2.0929e+00, -8.8039e-01, -6.1725e-01, -2.3152e+00,\n",
       "         -2.8114e+00, -1.7393e+00, -1.5557e+00,  1.0327e-01, -9.3297e-01,\n",
       "         -2.5677e-01, -1.0710e+00, -3.1294e-01, -1.9436e-01, -9.6809e-01,\n",
       "         -1.7714e+00,  1.5691e+00,  3.9849e-01,  1.1620e-01,  2.7817e-01,\n",
       "         -1.6774e+00, -2.4437e+00, -3.7204e-01, -5.0031e-01, -1.3366e+00,\n",
       "          1.4755e+00, -5.6520e-01, -9.0792e-01,  3.2421e+00,  2.2167e-01,\n",
       "         -3.8097e+00, -1.7336e+00, -1.4178e+00,  2.0427e+00,  4.6043e+00,\n",
       "         -9.1022e-01,  1.4626e+00,  1.2146e+00, -1.2792e+00,  1.0550e+00,\n",
       "          2.0324e-01, -6.6385e-01, -3.1419e+00, -2.4835e+00,  3.5382e+00,\n",
       "         -2.9491e+00,  7.7497e-01,  3.2320e+00, -3.6188e-01, -1.9962e+00,\n",
       "         -1.9450e+00,  5.8005e+00,  1.3727e+00,  1.9450e-01,  1.9389e+00,\n",
       "         -7.8413e-01, -2.3023e+00,  4.0100e+00,  5.1607e-01, -1.5264e+00,\n",
       "          4.2022e-01, -4.2947e-01,  2.0527e+00,  1.1560e+00, -1.9284e+00,\n",
       "          6.5214e-01, -6.0714e-01,  1.3180e+00, -3.1802e+00,  4.3240e-01,\n",
       "         -1.1334e+00, -2.4962e+00,  3.0560e+00,  2.3637e+00, -4.3262e-02,\n",
       "          2.0289e+00,  3.3392e-02, -1.9774e+00, -1.2191e+00, -6.4918e-01,\n",
       "          2.3709e-01, -3.5402e+00, -7.2311e-01,  1.1711e+00,  6.1030e-01,\n",
       "         -1.6296e+00,  2.5986e+00, -1.1936e+00, -1.2215e+00, -6.6957e-01,\n",
       "         -4.1109e-01, -1.0610e+00, -1.9270e+00, -8.6841e-01,  3.6220e+00,\n",
       "          1.2385e+00,  2.1272e+00, -5.8916e-01, -3.1628e+00,  1.7204e+00,\n",
       "          4.8532e-01,  3.3709e-01,  6.5006e-01,  6.1383e-01, -1.5552e+00,\n",
       "          2.2256e+00,  2.5215e+00, -1.7868e+00, -4.8270e-01,  7.9622e-01,\n",
       "         -8.7014e-01,  3.0588e-01, -1.0133e+00,  6.5294e-01,  4.9481e+00,\n",
       "          2.8764e+00, -1.5196e-01,  6.2802e-01, -2.1823e-01, -2.4289e+00,\n",
       "         -2.0553e+00,  4.8433e-01, -2.8288e+00, -1.6123e+00,  1.1191e+00,\n",
       "         -1.9261e+00, -1.1332e+00,  2.1884e+00, -1.7590e-01, -1.7990e+00,\n",
       "         -1.2496e+00,  1.7520e+00,  7.3966e-01,  7.8001e-01,  1.3240e+00,\n",
       "          1.4956e+00,  4.0413e-01, -3.8623e-02,  5.5902e-02,  2.8074e+00,\n",
       "         -9.4952e-01,  2.8908e+00, -3.4154e-01, -8.5200e-01,  3.0531e-02,\n",
       "          1.2131e+00,  1.3106e+00, -3.3540e+00, -3.1847e-01, -1.8666e+00,\n",
       "          2.9112e+00, -1.5765e+00,  1.3699e+00,  9.2533e-01,  1.3614e+00,\n",
       "         -2.1257e+00, -2.7830e+00,  6.4333e-01, -1.8123e+00,  2.3022e+00,\n",
       "         -1.0100e+00, -7.1910e-01, -1.9386e-01, -2.9554e-01,  2.7729e+00,\n",
       "         -6.2670e-01, -1.3307e+00,  7.7885e-01,  8.9479e-02, -7.0753e-01,\n",
       "         -2.3729e+00, -3.7888e+00,  1.6000e+00, -1.1635e+00,  9.1029e-01,\n",
       "         -1.6698e+00,  6.3770e-01,  1.7029e+00,  1.3891e+00, -1.2510e+00,\n",
       "         -1.4784e+00, -1.2687e+00, -2.3580e+00,  3.0427e+00,  8.9101e-01,\n",
       "         -2.5956e+00, -2.7691e+00,  1.0993e+00,  8.3269e-01, -1.2010e+00,\n",
       "          2.0196e+00,  2.6156e+00, -8.7581e-01, -1.4950e+00, -4.5015e-01,\n",
       "          2.2951e+00,  6.7730e-01, -3.9076e-01,  6.0905e-01,  1.1659e+00,\n",
       "         -3.2360e+00, -1.0513e+00, -1.3538e-02, -3.8802e-01,  9.8418e-01,\n",
       "         -4.5433e-01,  1.2388e+00,  3.5969e+00, -1.1797e+00,  5.4718e-01,\n",
       "         -1.1665e+00,  1.6823e+00, -3.7905e+00, -9.6648e-01, -6.9550e-01,\n",
       "         -1.0516e+00,  3.3119e+00,  1.3266e+00, -5.4267e-01, -2.7312e+00,\n",
       "          1.5747e+00, -3.3714e+00,  1.3596e+00,  1.6099e+00, -1.4596e+00,\n",
       "         -1.4525e+00,  1.0218e+00, -1.0482e+00,  1.9353e+00, -3.4888e+00,\n",
       "          5.3827e+00, -3.4812e-01,  4.2275e-01,  1.9091e+00, -2.0791e+00,\n",
       "         -1.3947e+00,  4.7071e+00, -2.5628e-01, -1.0625e+00,  5.1826e-01,\n",
       "         -6.6170e-01, -8.0670e-01,  5.7555e-01,  1.5184e+00,  3.0724e+00,\n",
       "          7.3266e-01, -2.8142e+00,  8.0727e-01, -1.2539e-01, -4.2979e-04,\n",
       "          8.7256e-02,  1.1418e+00, -1.2254e+00,  3.4860e-02, -1.6045e+00,\n",
       "          1.0208e+00, -1.0910e+00, -1.5703e+00, -1.5526e+00,  1.3836e+00,\n",
       "         -4.0606e-01, -5.7976e-01,  2.1950e-02, -4.1726e-01,  5.1170e-01,\n",
       "         -2.8291e+00,  1.8855e-01,  7.0472e-01,  8.6535e-01, -1.6697e+00,\n",
       "          4.0714e+00,  3.2533e-01, -3.3628e-01,  1.0309e+00, -2.6324e-01,\n",
       "         -1.3544e+00, -5.5024e-01,  3.3779e+00,  9.6194e-01, -8.3857e-02,\n",
       "         -8.3281e-01, -1.5663e+00,  9.7835e-01, -2.0795e+00, -6.5491e-05,\n",
       "         -6.9422e-01,  1.2601e+00,  1.7708e+00,  4.5781e-03,  5.7046e+00,\n",
       "         -4.9818e-01,  3.3184e-01,  3.3695e-01, -1.5589e+00,  9.8003e-01,\n",
       "         -2.3342e+00, -1.6011e-01, -1.2632e+00, -1.0732e+00,  3.4990e-01,\n",
       "         -1.2606e-01, -1.3809e-01,  1.0654e+00,  1.1554e-01,  1.6180e+00,\n",
       "         -1.3280e+00,  2.5532e+00,  3.4658e-01,  9.5017e-01, -2.0818e+00,\n",
       "          4.4122e+00,  1.5756e+00, -3.0372e+00,  2.8966e+00,  1.7707e+00,\n",
       "         -1.4800e+00, -1.0049e+00,  7.5218e-01, -6.1105e-01,  6.3843e+00,\n",
       "         -1.2737e+00, -4.6841e-01,  2.1256e+00,  3.1489e+00, -1.4624e+00,\n",
       "         -2.4909e+00, -6.3433e-01, -1.0046e+00, -2.5122e+00,  7.3233e-01,\n",
       "         -2.3670e-01, -2.1953e-01,  9.7460e-01, -7.5803e-01, -1.8028e-01,\n",
       "          1.6692e+00,  1.3294e+00,  1.2756e+00,  1.2003e+00,  1.8692e+00,\n",
       "          6.4025e-01,  2.6855e+00, -2.4448e+00, -6.5681e-01, -7.3068e-02,\n",
       "         -6.3768e-02,  2.3694e+00,  3.0941e+00, -4.8212e-01,  3.2302e+00,\n",
       "          1.0442e+00, -3.8804e+00,  9.3278e-02,  7.9129e-01,  1.3928e+00,\n",
       "         -1.8126e+00,  1.9535e+00,  1.1905e+00, -2.9106e+00, -3.2048e+00,\n",
       "         -3.3975e+00, -2.3265e-01, -5.9272e-01,  4.3384e+00, -8.0996e-01,\n",
       "          4.0042e-01, -1.7034e+00,  1.6531e+00, -1.9187e+00, -3.3676e+00,\n",
       "         -3.8851e-01,  1.6537e+00, -5.8401e-01, -2.7501e+00,  3.4808e+00,\n",
       "          7.7536e-01, -5.9660e-01,  1.0315e+00,  2.4990e+00,  6.4720e-01,\n",
       "          5.3384e+00, -3.3235e-01,  9.8246e-01, -1.3351e-01,  4.4544e-01,\n",
       "         -1.8361e+00, -1.6700e+00,  2.5674e+00,  1.5662e+00,  1.2231e+00,\n",
       "         -1.7750e+00,  1.4633e+00,  1.5787e-01,  6.3129e-01,  1.5457e-01,\n",
       "          1.1962e+00, -4.3923e-01, -9.3171e-01,  2.2134e+00,  5.9288e+00,\n",
       "          2.3100e+00, -1.1576e-01,  1.0802e+00,  1.6675e+00,  2.3477e+00,\n",
       "          1.2307e+00,  5.4176e+00,  4.3612e-01, -6.4280e-01, -1.9437e+00,\n",
       "         -4.8482e-01,  1.3567e+00,  1.0032e+00, -4.0972e-01,  7.0287e-01,\n",
       "          2.3384e+00,  5.0812e+00,  2.2726e+00, -4.4493e-01, -1.7887e+00,\n",
       "          1.5642e+00, -9.7132e-01, -1.8365e+00, -9.2089e-01,  1.2248e+00,\n",
       "         -4.7061e-01, -2.8870e-01, -1.1714e+00, -7.6508e-01, -1.3018e+00,\n",
       "         -6.5163e-01, -4.7126e-01,  1.1225e+00, -1.4029e+00,  1.1229e-01,\n",
       "          1.4404e+00,  8.5704e-01, -1.9319e-01,  1.8519e-01, -2.3226e+00,\n",
       "         -1.2973e-01, -1.2144e+00,  2.6409e+00,  1.5501e+00,  5.0892e-01,\n",
       "          3.6473e+00,  3.4411e+00,  2.1215e+00,  4.8143e-01,  7.7007e-01,\n",
       "          2.0927e+00, -2.5469e+00,  1.0864e+00,  1.5447e+00, -2.1742e+00,\n",
       "         -5.0686e-01,  6.3574e-02,  1.3251e-01,  7.5917e-01, -4.0784e-01,\n",
       "         -1.9478e+00,  1.7251e+00,  1.4386e+00,  7.5673e-01, -2.1862e-01,\n",
       "         -4.3077e-01,  3.9524e+00, -6.6474e-01,  5.2645e+00,  1.9075e+00,\n",
       "          2.0899e+00, -7.8763e-01,  2.2569e+00,  1.1972e+00,  3.1352e-01,\n",
       "          5.4835e+00, -6.7625e-01,  1.0413e+00,  1.8586e+00,  9.9627e-01,\n",
       "          1.1532e+00, -2.3391e-01,  2.4709e+00,  1.9568e-01,  9.5130e-01,\n",
       "          1.9092e+00,  2.8709e+00,  1.6227e+00, -1.4375e+00, -7.6736e-01,\n",
       "          2.9744e-01,  2.6290e-01,  1.9373e+00,  2.3169e+00,  9.0204e-01]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Torchscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/anaconda3/envs/torch_cv_env/lib/python3.11/site-packages/torch/jit/_script.py:1277: UserWarning: `optimize` is deprecated and has no effect. Use `with torch.jit.optimized_execution() instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "example = open(\"models/vgg_torchscript.jit\", \"wb\")\n",
    "script = torch.jit.script(model, cuda_input_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "script.save(\"models/vgg_torchscript.jit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=VGG\n",
       "  (features): RecursiveScriptModule(\n",
       "    original_name=Sequential\n",
       "    (0): RecursiveScriptModule(original_name=Conv2d)\n",
       "    (1): RecursiveScriptModule(original_name=ReLU)\n",
       "    (2): RecursiveScriptModule(original_name=Conv2d)\n",
       "    (3): RecursiveScriptModule(original_name=ReLU)\n",
       "    (4): RecursiveScriptModule(original_name=MaxPool2d)\n",
       "    (5): RecursiveScriptModule(original_name=Conv2d)\n",
       "    (6): RecursiveScriptModule(original_name=ReLU)\n",
       "    (7): RecursiveScriptModule(original_name=Conv2d)\n",
       "    (8): RecursiveScriptModule(original_name=ReLU)\n",
       "    (9): RecursiveScriptModule(original_name=MaxPool2d)\n",
       "    (10): RecursiveScriptModule(original_name=Conv2d)\n",
       "    (11): RecursiveScriptModule(original_name=ReLU)\n",
       "    (12): RecursiveScriptModule(original_name=Conv2d)\n",
       "    (13): RecursiveScriptModule(original_name=ReLU)\n",
       "    (14): RecursiveScriptModule(original_name=Conv2d)\n",
       "    (15): RecursiveScriptModule(original_name=ReLU)\n",
       "    (16): RecursiveScriptModule(original_name=MaxPool2d)\n",
       "    (17): RecursiveScriptModule(original_name=Conv2d)\n",
       "    (18): RecursiveScriptModule(original_name=ReLU)\n",
       "    (19): RecursiveScriptModule(original_name=Conv2d)\n",
       "    (20): RecursiveScriptModule(original_name=ReLU)\n",
       "    (21): RecursiveScriptModule(original_name=Conv2d)\n",
       "    (22): RecursiveScriptModule(original_name=ReLU)\n",
       "    (23): RecursiveScriptModule(original_name=MaxPool2d)\n",
       "    (24): RecursiveScriptModule(original_name=Conv2d)\n",
       "    (25): RecursiveScriptModule(original_name=ReLU)\n",
       "    (26): RecursiveScriptModule(original_name=Conv2d)\n",
       "    (27): RecursiveScriptModule(original_name=ReLU)\n",
       "    (28): RecursiveScriptModule(original_name=Conv2d)\n",
       "    (29): RecursiveScriptModule(original_name=ReLU)\n",
       "    (30): RecursiveScriptModule(original_name=MaxPool2d)\n",
       "  )\n",
       "  (avgpool): RecursiveScriptModule(original_name=AdaptiveAvgPool2d)\n",
       "  (classifier): RecursiveScriptModule(\n",
       "    original_name=Sequential\n",
       "    (0): RecursiveScriptModule(original_name=Linear)\n",
       "    (1): RecursiveScriptModule(original_name=ReLU)\n",
       "    (2): RecursiveScriptModule(original_name=Dropout)\n",
       "    (3): RecursiveScriptModule(original_name=Linear)\n",
       "    (4): RecursiveScriptModule(original_name=ReLU)\n",
       "    (5): RecursiveScriptModule(original_name=Dropout)\n",
       "    (6): RecursiveScriptModule(original_name=Linear)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_vgg = torch.jit.load(\"models/vgg_torchscript.jit\")\n",
    "script_vgg.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/anaconda3/envs/torch_cv_env/lib/python3.11/site-packages/torch/onnx/utils.py:847: UserWarning: no signature found for <torch.ScriptMethod object at 0x7f16f893bbf0>, skipping _decide_input_format\n",
      "  warnings.warn(f\"{e}, skipping _decide_input_format\")\n"
     ]
    },
    {
     "ename": "SymbolicValueError",
     "evalue": "Unsupported: ONNX export of operator adaptive_avg_pool2d, output size that are not factor of input size. Please feel free to request support or submit a pull request on PyTorch GitHub: https://github.com/pytorch/pytorch/issues  [Caused by the value '34 defined in (%34 : Long(2, strides=[1], device=cpu) = onnx::Constant[value= 7  7 [ CPULongType{2} ]]()\n)' (type 'Tensor') in the TorchScript graph. The containing node has kind 'onnx::Constant'.] \n\n    Inputs:\n        Empty\n    Outputs:\n        #0: 34 defined in (%34 : Long(2, strides=[1], device=cpu) = onnx::Constant[value= 7  7 [ CPULongType{2} ]]()\n    )  (type 'Tensor')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSymbolicValueError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/home/james/faster_ml/ONNX/VGG-16_Pytorch.ipynb Cell 31\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/james/faster_ml/ONNX/VGG-16_Pytorch.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmodels/vgg_torch.onnx\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/james/faster_ml/ONNX/VGG-16_Pytorch.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m torch\u001b[39m.\u001b[39;49monnx\u001b[39m.\u001b[39;49mexport(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/james/faster_ml/ONNX/VGG-16_Pytorch.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     script_vgg, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/james/faster_ml/ONNX/VGG-16_Pytorch.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     cuda_input_final, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/james/faster_ml/ONNX/VGG-16_Pytorch.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     path)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_cv_env/lib/python3.11/site-packages/torch/onnx/utils.py:516\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39m@_beartype\u001b[39m\u001b[39m.\u001b[39mbeartype\n\u001b[1;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexport\u001b[39m(\n\u001b[1;32m    191\u001b[0m     model: Union[torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule, torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mScriptModule, torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mScriptFunction],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m     autograd_inlining: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    209\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \n\u001b[1;32m    212\u001b[0m \u001b[39m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[39m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m     _export(\n\u001b[1;32m    517\u001b[0m         model,\n\u001b[1;32m    518\u001b[0m         args,\n\u001b[1;32m    519\u001b[0m         f,\n\u001b[1;32m    520\u001b[0m         export_params,\n\u001b[1;32m    521\u001b[0m         verbose,\n\u001b[1;32m    522\u001b[0m         training,\n\u001b[1;32m    523\u001b[0m         input_names,\n\u001b[1;32m    524\u001b[0m         output_names,\n\u001b[1;32m    525\u001b[0m         operator_export_type\u001b[39m=\u001b[39;49moperator_export_type,\n\u001b[1;32m    526\u001b[0m         opset_version\u001b[39m=\u001b[39;49mopset_version,\n\u001b[1;32m    527\u001b[0m         do_constant_folding\u001b[39m=\u001b[39;49mdo_constant_folding,\n\u001b[1;32m    528\u001b[0m         dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes,\n\u001b[1;32m    529\u001b[0m         keep_initializers_as_inputs\u001b[39m=\u001b[39;49mkeep_initializers_as_inputs,\n\u001b[1;32m    530\u001b[0m         custom_opsets\u001b[39m=\u001b[39;49mcustom_opsets,\n\u001b[1;32m    531\u001b[0m         export_modules_as_functions\u001b[39m=\u001b[39;49mexport_modules_as_functions,\n\u001b[1;32m    532\u001b[0m         autograd_inlining\u001b[39m=\u001b[39;49mautograd_inlining,\n\u001b[1;32m    533\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_cv_env/lib/python3.11/site-packages/torch/onnx/utils.py:1596\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m   1593\u001b[0m     dynamic_axes \u001b[39m=\u001b[39m {}\n\u001b[1;32m   1594\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1596\u001b[0m graph, params_dict, torch_out \u001b[39m=\u001b[39m _model_to_graph(\n\u001b[1;32m   1597\u001b[0m     model,\n\u001b[1;32m   1598\u001b[0m     args,\n\u001b[1;32m   1599\u001b[0m     verbose,\n\u001b[1;32m   1600\u001b[0m     input_names,\n\u001b[1;32m   1601\u001b[0m     output_names,\n\u001b[1;32m   1602\u001b[0m     operator_export_type,\n\u001b[1;32m   1603\u001b[0m     val_do_constant_folding,\n\u001b[1;32m   1604\u001b[0m     fixed_batch_size\u001b[39m=\u001b[39;49mfixed_batch_size,\n\u001b[1;32m   1605\u001b[0m     training\u001b[39m=\u001b[39;49mtraining,\n\u001b[1;32m   1606\u001b[0m     dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes,\n\u001b[1;32m   1607\u001b[0m )\n\u001b[1;32m   1609\u001b[0m \u001b[39m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m   1610\u001b[0m defer_weight_export \u001b[39m=\u001b[39m (\n\u001b[1;32m   1611\u001b[0m     export_type \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m _exporter_states\u001b[39m.\u001b[39mExportTypes\u001b[39m.\u001b[39mPROTOBUF_FILE\n\u001b[1;32m   1612\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_cv_env/lib/python3.11/site-packages/torch/onnx/utils.py:1139\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1136\u001b[0m params_dict \u001b[39m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[1;32m   1138\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1139\u001b[0m     graph \u001b[39m=\u001b[39m _optimize_graph(\n\u001b[1;32m   1140\u001b[0m         graph,\n\u001b[1;32m   1141\u001b[0m         operator_export_type,\n\u001b[1;32m   1142\u001b[0m         _disable_torch_constant_prop\u001b[39m=\u001b[39;49m_disable_torch_constant_prop,\n\u001b[1;32m   1143\u001b[0m         fixed_batch_size\u001b[39m=\u001b[39;49mfixed_batch_size,\n\u001b[1;32m   1144\u001b[0m         params_dict\u001b[39m=\u001b[39;49mparams_dict,\n\u001b[1;32m   1145\u001b[0m         dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes,\n\u001b[1;32m   1146\u001b[0m         input_names\u001b[39m=\u001b[39;49minput_names,\n\u001b[1;32m   1147\u001b[0m         module\u001b[39m=\u001b[39;49mmodule,\n\u001b[1;32m   1148\u001b[0m     )\n\u001b[1;32m   1149\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1150\u001b[0m     torch\u001b[39m.\u001b[39monnx\u001b[39m.\u001b[39mlog(\u001b[39m\"\u001b[39m\u001b[39mTorch IR graph at exception: \u001b[39m\u001b[39m\"\u001b[39m, graph)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_cv_env/lib/python3.11/site-packages/torch/onnx/utils.py:677\u001b[0m, in \u001b[0;36m_optimize_graph\u001b[0;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001b[0m\n\u001b[1;32m    674\u001b[0m     _C\u001b[39m.\u001b[39m_jit_pass_onnx_set_dynamic_input_shape(graph, dynamic_axes, input_names)\n\u001b[1;32m    675\u001b[0m _C\u001b[39m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[0;32m--> 677\u001b[0m graph \u001b[39m=\u001b[39m _C\u001b[39m.\u001b[39;49m_jit_pass_onnx(graph, operator_export_type)\n\u001b[1;32m    678\u001b[0m _C\u001b[39m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[1;32m    679\u001b[0m _C\u001b[39m.\u001b[39m_jit_pass_lint(graph)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_cv_env/lib/python3.11/site-packages/torch/onnx/utils.py:1940\u001b[0m, in \u001b[0;36m_run_symbolic_function\u001b[0;34m(graph, block, node, inputs, env, operator_export_type)\u001b[0m\n\u001b[1;32m   1935\u001b[0m     \u001b[39mif\u001b[39;00m symbolic_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1936\u001b[0m         \u001b[39m# TODO Wrap almost identical attrs assignment or comment the difference.\u001b[39;00m\n\u001b[1;32m   1937\u001b[0m         attrs \u001b[39m=\u001b[39m {\n\u001b[1;32m   1938\u001b[0m             k: symbolic_helper\u001b[39m.\u001b[39m_node_get(node, k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m node\u001b[39m.\u001b[39mattributeNames()\n\u001b[1;32m   1939\u001b[0m         }\n\u001b[0;32m-> 1940\u001b[0m         \u001b[39mreturn\u001b[39;00m symbolic_fn(graph_context, \u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mattrs)\n\u001b[1;32m   1942\u001b[0m attrs \u001b[39m=\u001b[39m {\n\u001b[1;32m   1943\u001b[0m     k \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39mkindOf(k)[\u001b[39m0\u001b[39m]: symbolic_helper\u001b[39m.\u001b[39m_node_get(node, k)\n\u001b[1;32m   1944\u001b[0m     \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m node\u001b[39m.\u001b[39mattributeNames()\n\u001b[1;32m   1945\u001b[0m }\n\u001b[1;32m   1946\u001b[0m \u001b[39mif\u001b[39;00m namespace \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39monnx\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1947\u001b[0m     \u001b[39m# Clone node to trigger ONNX shape inference\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_cv_env/lib/python3.11/site-packages/torch/onnx/symbolic_helper.py:395\u001b[0m, in \u001b[0;36mquantized_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(g, *args, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m         is_quantized\u001b[39m.\u001b[39mappend(_is_arg_quantized(descriptor, arg))\n\u001b[1;32m    394\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(is_quantized):\n\u001b[0;32m--> 395\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(g, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    397\u001b[0m \u001b[39m# Dequantize arguments that are quantized\u001b[39;00m\n\u001b[1;32m    398\u001b[0m non_quantized_args \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_cv_env/lib/python3.11/site-packages/torch/onnx/symbolic_opset9.py:1900\u001b[0m, in \u001b[0;36m_adaptive_pool.<locals>.symbolic_fn\u001b[0;34m(g, input, output_size)\u001b[0m\n\u001b[1;32m   1898\u001b[0m     \u001b[39mif\u001b[39;00m output_size \u001b[39m==\u001b[39m [\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(output_size):\n\u001b[1;32m   1899\u001b[0m         \u001b[39mreturn\u001b[39;00m g\u001b[39m.\u001b[39mop(\u001b[39m\"\u001b[39m\u001b[39mGlobalMaxPool\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39minput\u001b[39m), \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1900\u001b[0m     \u001b[39mreturn\u001b[39;00m symbolic_helper\u001b[39m.\u001b[39;49m_unimplemented(\n\u001b[1;32m   1901\u001b[0m         name, \u001b[39m\"\u001b[39;49m\u001b[39moutput size that are not factor of input size\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_size_value\n\u001b[1;32m   1902\u001b[0m     )\n\u001b[1;32m   1903\u001b[0m k \u001b[39m=\u001b[39m [\u001b[39mint\u001b[39m(dim[i] \u001b[39m/\u001b[39m output_size[i]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(dim))]\n\u001b[1;32m   1904\u001b[0m \u001b[39m# call max_poolxd_with_indices to get indices in the output\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_cv_env/lib/python3.11/site-packages/torch/onnx/symbolic_helper.py:612\u001b[0m, in \u001b[0;36m_unimplemented\u001b[0;34m(op, msg, value)\u001b[0m\n\u001b[1;32m    610\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mONNX export failed on \u001b[39m\u001b[39m{\u001b[39;00mop\u001b[39m}\u001b[39;00m\u001b[39m because \u001b[39m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m not supported\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    611\u001b[0m \u001b[39melif\u001b[39;00m GLOBALS\u001b[39m.\u001b[39moperator_export_type \u001b[39m==\u001b[39m _C_onnx\u001b[39m.\u001b[39mOperatorExportTypes\u001b[39m.\u001b[39mONNX:\n\u001b[0;32m--> 612\u001b[0m     _onnx_unsupported(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mop\u001b[39m}\u001b[39;49;00m\u001b[39m, \u001b[39;49m\u001b[39m{\u001b[39;49;00mmsg\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, value)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_cv_env/lib/python3.11/site-packages/torch/onnx/symbolic_helper.py:623\u001b[0m, in \u001b[0;36m_onnx_unsupported\u001b[0;34m(op_name, value)\u001b[0m\n\u001b[1;32m    617\u001b[0m message \u001b[39m=\u001b[39m (\n\u001b[1;32m    618\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnsupported: ONNX export of operator \u001b[39m\u001b[39m{\u001b[39;00mop_name\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    619\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPlease feel free to request support or submit a pull request \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    620\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mon PyTorch GitHub: \u001b[39m\u001b[39m{\u001b[39;00m_constants\u001b[39m.\u001b[39mPYTORCH_GITHUB_ISSUES_URL\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    621\u001b[0m )\n\u001b[1;32m    622\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, _C\u001b[39m.\u001b[39mValue):\n\u001b[0;32m--> 623\u001b[0m     \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mSymbolicValueError(\n\u001b[1;32m    624\u001b[0m         message,\n\u001b[1;32m    625\u001b[0m         value,\n\u001b[1;32m    626\u001b[0m     )\n\u001b[1;32m    627\u001b[0m \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mOnnxExporterError(message)\n",
      "\u001b[0;31mSymbolicValueError\u001b[0m: Unsupported: ONNX export of operator adaptive_avg_pool2d, output size that are not factor of input size. Please feel free to request support or submit a pull request on PyTorch GitHub: https://github.com/pytorch/pytorch/issues  [Caused by the value '34 defined in (%34 : Long(2, strides=[1], device=cpu) = onnx::Constant[value= 7  7 [ CPULongType{2} ]]()\n)' (type 'Tensor') in the TorchScript graph. The containing node has kind 'onnx::Constant'.] \n\n    Inputs:\n        Empty\n    Outputs:\n        #0: 34 defined in (%34 : Long(2, strides=[1], device=cpu) = onnx::Constant[value= 7  7 [ CPULongType{2} ]]()\n    )  (type 'Tensor')"
     ]
    }
   ],
   "source": [
    "path = \"models/vgg_torch.onnx\"\n",
    "torch.onnx.export(\n",
    "    script_vgg, \n",
    "    cuda_input_final, \n",
    "    path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matchmylook_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
